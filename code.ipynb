{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a46cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e53d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175bffc",
   "metadata": {},
   "source": [
    "<h3>ETAPA 0 - Leitura do CSV (com checagens)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbb1e4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Lido com encoding: utf-8\n",
      "\n",
      "[INFO] Formato do DataFrame: (802, 24)\n",
      "[INFO] Primeiras colunas: ['Name (Remove)', 'Size', 'Type', 'Align. (Remove)', 'AC (Remove)', 'HP (Remove)', 'Speeds (Remove)', 'STR (Remove)', 'DEX (Remove)', 'CON (Remove)']\n",
      "\n",
      "[INFO] Amostra (5 linhas):\n",
      "          Name (Remove)    Size              Type Align. (Remove) AC (Remove)  \\\n",
      "0             Aarakocra  Medium          Humanoid              NG          12   \n",
      "1               Aboleth   Large        Aberration              LE          17   \n",
      "2  Albino Dwarf Warrior  Medium  Humanoid (Dwarf)             ANY          13   \n",
      "3  Aldani (Lobsterfolk)  Medium       Monstrosity              LN          14   \n",
      "4                 Allip  Medium            Undead              NE          13   \n",
      "\n",
      "  HP (Remove) Speeds (Remove) STR (Remove) DEX (Remove) CON (Remove)  ...  \\\n",
      "0          13      20, 50 fly           10           14           10  ...   \n",
      "1         135     10, swim 40           21            9           15  ...   \n",
      "2          30              25           13           13           17  ...   \n",
      "3          49     20, swim 30           13            8           12  ...   \n",
      "4          40          fly 40            6           17           10  ...   \n",
      "\n",
      "                 Skills (Remove)  \\\n",
      "0                     Perception   \n",
      "1            History, Perception   \n",
      "2  Perception, Stealth, Survival   \n",
      "3           Perception, Survival   \n",
      "4            Perception, Stealth   \n",
      "\n",
      "                                        WRI (Remove) Senses (Remove)  \\\n",
      "0                                                NaN          Normal   \n",
      "1                                                NaN  Darkvision 120   \n",
      "2                                          Poisonres   Darkvision 60   \n",
      "3                                                NaN   Darkvision 60   \n",
      "4  Acidres, fireres, lightningres, thunderres, no...   Darkvision 60   \n",
      "\n",
      "           Languages (Remove)     CR  \\\n",
      "0                       Auran   0.25   \n",
      "1  Deep Speech, Telepathy 120  10.00   \n",
      "2            Common, Dwarvish   0.25   \n",
      "3                      Common   1.00   \n",
      "4                         Any   5.00   \n",
      "\n",
      "                                 Additional (Remove)  \\\n",
      "0                                        Dive Attack   \n",
      "1  Amphibious,  Mucous Cloud, Probing Telepathy, ...   \n",
      "2                                 Dwarven Resilience   \n",
      "3                                         Amphibious   \n",
      "4                               Incorporeal Movement   \n",
      "\n",
      "                 Font (Remove) Additional Info (Remove)       Author (Remove)  \\\n",
      "0               Monster Manual                      NaN  Wizards of the Coast   \n",
      "1               Monster Manual                      NaN  Wizards of the Coast   \n",
      "2         Tomb of Annihilation                      NaN  Wizards of the Coast   \n",
      "3         Tomb of Annihilation                      NaN  Wizards of the Coast   \n",
      "4  Mordenkainen's Tome of Foes                      NaN  Wizards of the Coast   \n",
      "\n",
      "                   Environment  \n",
      "0   Forest, Plains, Sky, Urban  \n",
      "1  Dungeon, Underground, Water  \n",
      "2        Forest, Plains, Urban  \n",
      "3      Forest, Mountain, Water  \n",
      "4                 Dungeon, Sky  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "[DETECÇÃO DE COLUNAS]\n",
      "Type: Type\n",
      "Environment: Environment\n",
      "CR: CR\n",
      "Size: Size\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = Path(\"input.csv\")\n",
    "\n",
    "assert CSV_PATH.exists(), f\"Arquivo não encontrado: {CSV_PATH.resolve()}\"\n",
    "\n",
    "# Tentativas de leitura com encodings comuns\n",
    "encodings_to_try = [\"utf-8\", \"utf-8-sig\", \"latin-1\"]\n",
    "last_err = None\n",
    "df = None\n",
    "for enc in encodings_to_try:\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_PATH, encoding=enc)\n",
    "        print(f\"[OK] Lido com encoding: {enc}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "\n",
    "if df is None:\n",
    "    raise RuntimeError(f\"Falha ao ler CSV. Último erro: {last_err}\")\n",
    "\n",
    "# Mostra um resumo rápido\n",
    "print(\"\\n[INFO] Formato do DataFrame:\", df.shape)\n",
    "print(\"[INFO] Primeiras colunas:\", list(df.columns[:10]))\n",
    "print(\"\\n[INFO] Amostra (5 linhas):\")\n",
    "print(df.head(5))\n",
    "\n",
    "# Helper para localizar colunas mesmo com sufixos (ex.: 'Type (Remove)')\n",
    "def find_col(cols, key):\n",
    "    key = key.lower()\n",
    "    for c in cols:\n",
    "        if key in c.lower():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Detecta as colunas principais (só para conferência visual nesta etapa)\n",
    "col_type  = find_col(df.columns, \"Type\")\n",
    "col_env   = find_col(df.columns, \"Environment\")\n",
    "col_cr    = find_col(df.columns, \"CR\")\n",
    "col_size  = find_col(df.columns, \"Size\")\n",
    "\n",
    "print(\"\\n[DETECÇÃO DE COLUNAS]\")\n",
    "print(\"Type:\", col_type)\n",
    "print(\"Environment:\", col_env)\n",
    "print(\"CR:\", col_cr)\n",
    "print(\"Size:\", col_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe75c78",
   "metadata": {},
   "source": [
    "<h3>ETAPA 1 - Seleção de colunas essenciais</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10ee64c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Colunas essenciais selecionadas:\n",
      "      type -> Type\n",
      "       env -> Environment\n",
      "        cr -> CR\n",
      "      size -> Size\n",
      "\n",
      "[INFO] DataFrame de trabalho criado.\n",
      "[INFO] Formato: (802, 4)\n",
      "[INFO] Colunas: ['Type', 'Environment', 'CR', 'Size']\n",
      "\n",
      "Prévia:\n",
      "               Type                  Environment     CR    Size\n",
      "0          Humanoid   Forest, Plains, Sky, Urban   0.25  Medium\n",
      "1        Aberration  Dungeon, Underground, Water  10.00   Large\n",
      "2  Humanoid (Dwarf)        Forest, Plains, Urban   0.25  Medium\n",
      "3       Monstrosity      Forest, Mountain, Water   1.00  Medium\n",
      "4            Undead                 Dungeon, Sky   5.00  Medium\n",
      "5             Beast               Forest, Plains   0.00   Small\n",
      "6            Dragon                Mountain, Sky   0.50  Medium\n",
      "7         Celestial                  Plains, Sky  10.00  Medium\n",
      "8         Celestial                  Plains, Sky  16.00   Large\n",
      "9         Celestial                  Plains, Sky  21.00   Large\n"
     ]
    }
   ],
   "source": [
    "# Dicionário com nomes detectados (da etapa anterior)\n",
    "ESSENTIALS = {\n",
    "    \"type\": col_type,\n",
    "    \"env\": col_env,\n",
    "    \"cr\": col_cr,\n",
    "    \"size\": col_size\n",
    "}\n",
    "\n",
    "print(\"\\n[INFO] Colunas essenciais selecionadas:\")\n",
    "for k, v in ESSENTIALS.items():\n",
    "    print(f\"  {k:>8} -> {v}\")\n",
    "\n",
    "# Cria uma cópia só com essas colunas\n",
    "df_work = df[[v for v in ESSENTIALS.values() if v is not None]].copy()\n",
    "\n",
    "print(\"\\n[INFO] DataFrame de trabalho criado.\")\n",
    "print(\"[INFO] Formato:\", df_work.shape)\n",
    "print(\"[INFO] Colunas:\", list(df_work.columns))\n",
    "print(\"\\nPrévia:\")\n",
    "print(df_work.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c8835",
   "metadata": {},
   "source": [
    "<h3>ETAPA 2 - Limpeza e transformação dos dados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e94c9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETAPA 2 - Iniciando Limpeza e Transformação...\n",
      "[INFO] Duplicatas removidas: 315\n",
      "[INFO] Visualização dos dados limpos:\n",
      "          Type                  Environment     CR    Size  CR_float\n",
      "0     Humanoid   Forest, Plains, Sky, Urban   0.25  Medium      0.25\n",
      "1   Aberration  Dungeon, Underground, Water  10.00   Large     10.00\n",
      "2     Humanoid        Forest, Plains, Urban   0.25  Medium      0.25\n",
      "3  Monstrosity      Forest, Mountain, Water   1.00  Medium      1.00\n",
      "4       Undead                 Dungeon, Sky   5.00  Medium      5.00\n",
      "5        Beast               Forest, Plains   0.00   Small      0.00\n",
      "6       Dragon                Mountain, Sky   0.50  Medium      0.50\n",
      "7    Celestial                  Plains, Sky  10.00  Medium     10.00\n",
      "8    Celestial                  Plains, Sky  16.00   Large     16.00\n",
      "9    Celestial                  Plains, Sky  21.00   Large     21.00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nETAPA 2 - Iniciando Limpeza e Transformação...\")\n",
    "\n",
    "# Funções Auxiliares\n",
    "def parse_cr(x):\n",
    "    # converter valores de CR para float\n",
    "    s = str(x).strip()\n",
    "    if s in (\"nan\", \"\", \"—\", \"-\", \"None\"):\n",
    "        return np.nan\n",
    "    if \"/\" in s:\n",
    "        try:\n",
    "            a, b = s.split(\"/\", 1)\n",
    "            return float(a) / float(b)\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def clean_text_basic(s):\n",
    "    # Remove parenteses e normaliza o caps\n",
    "    s = re.sub(r\"\\(.*?\\)\", \"\", str(s))\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip().title()\n",
    "\n",
    "def normalize_env(env_str):\n",
    "    # padronizar ambientes (environment)\n",
    "    parts = [p.strip().title() for p in str(env_str).split(\",\") if p.strip()]\n",
    "    if not parts:\n",
    "        return \"Unknown\"\n",
    "    seen, out = set(), []\n",
    "    for p in parts:\n",
    "        if p not in seen:\n",
    "            seen.add(p)\n",
    "            out.append(p)\n",
    "    return \", \".join(out)\n",
    "\n",
    "#Aplicando limpeza\n",
    "df_work[\"Type\"] = df_work[\"Type\"].apply(clean_text_basic)\n",
    "df_work[\"Size\"] =  df_work[\"Size\"].apply(clean_text_basic)\n",
    "df_work[\"Environment\"] = df_work[\"Environment\"].apply(normalize_env)\n",
    "df_work[\"CR_float\"] = df_work[\"CR\"].apply(parse_cr)\n",
    "\n",
    "#Tratando valores faltantes\n",
    "df_work[\"CR_float\"] = df_work[\"CR_float\"].fillna(0.0)\n",
    "df_work[\"Environment\"] = df_work[\"Environment\"].replace(\"\", \"Unknown\")\n",
    "df_work[\"Type\"] = df_work[\"Type\"].replace(\"\", \"Unknown\")\n",
    "\n",
    "\n",
    "# Eliminar duplicatas\n",
    "before = len(df_work)\n",
    "df_work.drop_duplicates(inplace=True)\n",
    "after = len(df_work)\n",
    "\n",
    "print(f\"[INFO] Duplicatas removidas: {before - after}\")\n",
    "print(\"[INFO] Visualização dos dados limpos:\")\n",
    "print(df_work.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7744f83",
   "metadata": {},
   "source": [
    "<h3>ETAPA 3 - Transformação (one-hot e multi-one-hot)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27949ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETAPA 3 - Iniciando Transformação (one-hot e multi-one-hot)...\n",
      "[INFO] Preview das features: (487, 41)\n",
      "   MonsterID  CR_float  Type_Aberration  Type_Beast  Type_Celestial  \\\n",
      "0          1      0.25            False       False           False   \n",
      "1          2     10.00             True       False           False   \n",
      "2          3      0.25            False       False           False   \n",
      "3          4      1.00            False       False           False   \n",
      "4          5      5.00            False       False           False   \n",
      "\n",
      "   Type_Construct  Type_Dragon  Type_Elemental  Type_Fey  Type_Fiend  ...  \\\n",
      "0           False        False           False     False       False  ...   \n",
      "1           False        False           False     False       False  ...   \n",
      "2           False        False           False     False       False  ...   \n",
      "3           False        False           False     False       False  ...   \n",
      "4           False        False           False     False       False  ...   \n",
      "\n",
      "   env_Dungeon  env_Forest  env_Hell  env_Mountain  env_Plains  env_Sky  \\\n",
      "0            0           1         0             0           1        1   \n",
      "1            1           0         0             0           0        0   \n",
      "2            0           1         0             0           1        0   \n",
      "3            0           1         0             1           0        0   \n",
      "4            1           0         0             0           0        1   \n",
      "\n",
      "   env_Underground  env_Urban  env_Water  env_Unknown  \n",
      "0                0          1          0            0  \n",
      "1                1          0          1            0  \n",
      "2                0          1          0            0  \n",
      "3                0          0          1            0  \n",
      "4                0          0          0            0  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nETAPA 3 - Iniciando Transformação (one-hot e multi-one-hot)...\")\n",
    "\n",
    "#ID estavel apos a limpeza\n",
    "df_work= df_work.reset_index(drop=True)\n",
    "df_work.insert(0, \"MonsterID\", df_work.index + 1)\n",
    "\n",
    "#One-hot de 'Type' e 'Size'\n",
    "type_dummies = pd.get_dummies(df_work[\"Type\"], prefix=\"Type\")\n",
    "size_dummies = pd.get_dummies(df_work[\"Size\"], prefix=\"Size\")\n",
    "\n",
    "#Multi-one-hot de 'Environment'\n",
    "known_envs = [\"Arctic\", \"Cave\" , \"Desert\", \"Dungeon\", \"Forest\", \"Hell\", \"Mountain\", \"Plains\", \"Sky\", \"Underground\", \"Urban\", \"Water\", \"Unknown\"]\n",
    "\n",
    "def env_one_hot(env_str):\n",
    "    envs = [e.strip() for e in env_str.split(\",\") if e.strip()]\n",
    "    return {f\"env_{e}\": int(e in envs) for e in known_envs}\n",
    "\n",
    "env_dummies = df_work[\"Environment\"].apply(env_one_hot).apply(pd.Series)\n",
    "\n",
    "features = pd.concat([\n",
    "    df_work[[\"MonsterID\", \"CR_float\"]],\n",
    "    type_dummies,\n",
    "    size_dummies,\n",
    "    env_dummies\n",
    "], axis=1)\n",
    "\n",
    "print(\"[INFO] Preview das features:\",features.shape)\n",
    "print(features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cec9ed5",
   "metadata": {},
   "source": [
    "<h3>Exportação final</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4aa6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETAPA 4 - Exportação final...\n",
      "[INFO] Arquivos exportados:\n",
      "  - Limpo -> /home/ms.arthurhenrique/ms.arthurhenrique/Documentos/IA/Kraken/outputs/monsters_clean.csv\n",
      "  - Treino -> /home/ms.arthurhenrique/ms.arthurhenrique/Documentos/IA/Kraken/outputs/monsters_train.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nETAPA 4 - Exportação final...\")\n",
    "\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "monsters_clean_path = OUT_DIR / \"monsters_clean.csv\"\n",
    "monsters_train_path = OUT_DIR / \"monsters_train.csv\"\n",
    "\n",
    "df_clean = df_work[[\"MonsterID\", \"Type\", \"Size\", \"Environment\",\"CR\", \"CR_float\"]]\n",
    "df_clean.to_csv(monsters_clean_path, index=False)\n",
    "\n",
    "features.to_csv(monsters_train_path, index=False)\n",
    "\n",
    "print(f\"[INFO] Arquivos exportados:\")\n",
    "print(f\"  - Limpo -> {monsters_clean_path.resolve()}\")\n",
    "print(f\"  - Treino -> {monsters_train_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
